{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Package\n",
    "Uncomment the below line and run it to install the AI-agents package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiagents4pharma\n",
      "  Using cached aiagents4pharma-1.2.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting copasi_basico==0.78 (from aiagents4pharma)\n",
      "  Using cached copasi_basico-0.78-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting coverage==7.6.4 (from aiagents4pharma)\n",
      "  Using cached coverage-7.6.4-cp312-cp312-win_amd64.whl.metadata (8.4 kB)\n",
      "Collecting langchain==0.3.7 (from aiagents4pharma)\n",
      "  Using cached langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-community==0.3.5 (from aiagents4pharma)\n",
      "  Using cached langchain_community-0.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain-core==0.3.15 (from aiagents4pharma)\n",
      "  Using cached langchain_core-0.3.15-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-experimental==0.3.3 (from aiagents4pharma)\n",
      "  Using cached langchain_experimental-0.3.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting langchain-openai==0.2.5 (from aiagents4pharma)\n",
      "  Using cached langchain_openai-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting matplotlib==3.9.2 (from aiagents4pharma)\n",
      "  Using cached matplotlib-3.9.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting openai==1.55.3 (from aiagents4pharma)\n",
      "  Using cached openai-1.55.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting pandas==2.2.3 (from aiagents4pharma)\n",
      "  Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting plotly==5.24.1 (from aiagents4pharma)\n",
      "  Using cached plotly-5.24.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting pydantic==2.9.2 (from aiagents4pharma)\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting pylint==3.3.1 (from aiagents4pharma)\n",
      "  Using cached pylint-3.3.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pytest==8.3.3 (from aiagents4pharma)\n",
      "  Using cached pytest-8.3.3-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting streamlit==1.39.0 (from aiagents4pharma)\n",
      "  Using cached streamlit-1.39.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting tabulate==0.9.0 (from aiagents4pharma)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting tqdm==4.66.6 (from aiagents4pharma)\n",
      "  Using cached tqdm-4.66.6-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting python-copasi (from copasi_basico==0.78->aiagents4pharma)\n",
      "  Using cached python_copasi-4.45.296-cp312-cp312-win_amd64.whl.metadata (567 bytes)\n",
      "Collecting numpy (from copasi_basico==0.78->aiagents4pharma)\n",
      "  Using cached numpy-2.1.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from copasi_basico==0.78->aiagents4pharma) (6.0.2)\n",
      "Collecting scipy (from copasi_basico==0.78->aiagents4pharma)\n",
      "  Using cached scipy-1.14.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting lxml (from copasi_basico==0.78->aiagents4pharma)\n",
      "  Using cached lxml-5.3.0-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.3.7->aiagents4pharma)\n",
      "  Using cached SQLAlchemy-2.0.36-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.3.7->aiagents4pharma)\n",
      "  Using cached aiohttp-3.11.9-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain==0.3.7->aiagents4pharma)\n",
      "  Using cached langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.3.7->aiagents4pharma)\n",
      "  Using cached langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy (from copasi_basico==0.78->aiagents4pharma)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from langchain==0.3.7->aiagents4pharma) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain==0.3.7->aiagents4pharma)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.3.7->aiagents4pharma)\n",
      "  Using cached SQLAlchemy-2.0.35-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.3.5->aiagents4pharma)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community==0.3.5->aiagents4pharma)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community==0.3.5->aiagents4pharma)\n",
      "  Using cached pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core==0.3.15->aiagents4pharma)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from langchain-core==0.3.15->aiagents4pharma) (24.2)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core==0.3.15->aiagents4pharma)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.2.5->aiagents4pharma)\n",
      "  Using cached tiktoken-0.8.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib==3.9.2->aiagents4pharma)\n",
      "  Using cached contourpy-1.3.1-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.9.2->aiagents4pharma)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib==3.9.2->aiagents4pharma)\n",
      "  Using cached fonttools-4.55.2-cp312-cp312-win_amd64.whl.metadata (168 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib==3.9.2->aiagents4pharma)\n",
      "  Using cached kiwisolver-1.4.7-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Collecting pillow>=8 (from matplotlib==3.9.2->aiagents4pharma)\n",
      "  Using cached pillow-11.0.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib==3.9.2->aiagents4pharma)\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from matplotlib==3.9.2->aiagents4pharma) (2.9.0.post0)\n",
      "Collecting anyio<5,>=3.5.0 (from openai==1.55.3->aiagents4pharma)\n",
      "  Using cached anyio-4.7.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai==1.55.3->aiagents4pharma)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai==1.55.3->aiagents4pharma)\n",
      "  Using cached httpx-0.28.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai==1.55.3->aiagents4pharma)\n",
      "  Using cached jiter-0.8.0-cp312-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai==1.55.3->aiagents4pharma)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pytz>=2020.1 (from pandas==2.2.3->aiagents4pharma)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas==2.2.3->aiagents4pharma)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic==2.9.2->aiagents4pharma)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic==2.9.2->aiagents4pharma)\n",
      "  Using cached pydantic_core-2.23.4-cp312-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: platformdirs>=2.2.0 in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from pylint==3.3.1->aiagents4pharma) (4.3.6)\n",
      "Collecting astroid<=3.4.0-dev0,>=3.3.4 (from pylint==3.3.1->aiagents4pharma)\n",
      "  Using cached astroid-3.3.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting isort!=5.13.0,<6,>=4.2.5 (from pylint==3.3.1->aiagents4pharma)\n",
      "  Using cached isort-5.13.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mccabe<0.8,>=0.6 (from pylint==3.3.1->aiagents4pharma)\n",
      "  Using cached mccabe-0.7.0-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting tomlkit>=0.10.1 (from pylint==3.3.1->aiagents4pharma)\n",
      "  Using cached tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting dill>=0.3.6 (from pylint==3.3.1->aiagents4pharma)\n",
      "  Using cached dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: colorama>=0.4.5 in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from pylint==3.3.1->aiagents4pharma) (0.4.6)\n",
      "Collecting iniconfig (from pytest==8.3.3->aiagents4pharma)\n",
      "  Using cached iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pluggy<2,>=1.5 (from pytest==8.3.3->aiagents4pharma)\n",
      "  Using cached pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit==1.39.0->aiagents4pharma)\n",
      "  Using cached altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit==1.39.0->aiagents4pharma)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit==1.39.0->aiagents4pharma)\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from streamlit==1.39.0->aiagents4pharma) (8.1.7)\n",
      "Collecting pillow>=8 (from matplotlib==3.9.2->aiagents4pharma)\n",
      "  Using cached pillow-10.4.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting protobuf<6,>=3.20 (from streamlit==1.39.0->aiagents4pharma)\n",
      "  Using cached protobuf-5.29.1-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting pyarrow>=7.0 (from streamlit==1.39.0->aiagents4pharma)\n",
      "  Using cached pyarrow-18.1.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting rich<14,>=10.14.0 (from streamlit==1.39.0->aiagents4pharma)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit==1.39.0->aiagents4pharma)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit==1.39.0->aiagents4pharma)\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit==1.39.0->aiagents4pharma)\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from streamlit==1.39.0->aiagents4pharma) (6.4.2)\n",
      "Collecting watchdog<6,>=2.1.5 (from streamlit==1.39.0->aiagents4pharma)\n",
      "  Using cached watchdog-5.0.3-py3-none-win_amd64.whl.metadata (41 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.7->aiagents4pharma)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.7->aiagents4pharma)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.7->aiagents4pharma) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.7->aiagents4pharma)\n",
      "  Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.7->aiagents4pharma)\n",
      "  Using cached multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.7->aiagents4pharma)\n",
      "  Using cached propcache-0.2.1-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.7->aiagents4pharma)\n",
      "  Using cached yarl-1.18.3-cp312-cp312-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.39.0->aiagents4pharma) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.39.0->aiagents4pharma) (4.23.0)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit==1.39.0->aiagents4pharma)\n",
      "  Using cached narwhals-1.15.2-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai==1.55.3->aiagents4pharma) (3.10)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.5->aiagents4pharma)\n",
      "  Using cached marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.5->aiagents4pharma)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.39.0->aiagents4pharma)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.55.3->aiagents4pharma) (2024.8.30)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.55.3->aiagents4pharma)\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.55.3->aiagents4pharma)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core==0.3.15->aiagents4pharma)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.7->aiagents4pharma)\n",
      "  Using cached orjson-3.10.12-cp312-none-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.7->aiagents4pharma)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.5->aiagents4pharma)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib==3.9.2->aiagents4pharma) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from requests<3,>=2->langchain==0.3.7->aiagents4pharma) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from requests<3,>=2->langchain==0.3.7->aiagents4pharma) (2.2.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from rich<14,>=10.14.0->streamlit==1.39.0->aiagents4pharma) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from rich<14,>=10.14.0->streamlit==1.39.0->aiagents4pharma) (2.18.0)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain==0.3.7->aiagents4pharma)\n",
      "  Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.5->aiagents4pharma) (2024.11.6)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.39.0->aiagents4pharma)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit==1.39.0->aiagents4pharma) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.39.0->aiagents4pharma) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.39.0->aiagents4pharma) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.39.0->aiagents4pharma) (0.22.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hadnesreenath\\documents\\project\\aiagents4pharma\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit==1.39.0->aiagents4pharma) (0.1.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.5->aiagents4pharma)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Using cached aiagents4pharma-1.2.1-py3-none-any.whl (19 kB)\n",
      "Using cached copasi_basico-0.78-py3-none-any.whl (187 kB)\n",
      "Using cached coverage-7.6.4-cp312-cp312-win_amd64.whl (210 kB)\n",
      "Using cached langchain-0.3.7-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_community-0.3.5-py3-none-any.whl (2.4 MB)\n",
      "Using cached langchain_core-0.3.15-py3-none-any.whl (408 kB)\n",
      "Using cached langchain_experimental-0.3.3-py3-none-any.whl (208 kB)\n",
      "Using cached langchain_openai-0.2.5-py3-none-any.whl (50 kB)\n",
      "Using cached matplotlib-3.9.2-cp312-cp312-win_amd64.whl (7.8 MB)\n",
      "Using cached openai-1.55.3-py3-none-any.whl (389 kB)\n",
      "Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/11.5 MB 7.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.9/11.5 MB 7.6 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.0/11.5 MB 8.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.1/11.5 MB 9.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.7/11.5 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 9.6 MB/s eta 0:00:00\n",
      "Downloading plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
      "   ---------------------------------------- 0.0/19.1 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 2.6/19.1 MB 13.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 4.7/19.1 MB 12.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 6.6/19.1 MB 10.9 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 8.9/19.1 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 10.7/19.1 MB 10.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 12.3/19.1 MB 9.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 14.4/19.1 MB 10.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 16.5/19.1 MB 9.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 18.4/19.1 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.1/19.1 MB 9.5 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Downloading pylint-3.3.1-py3-none-any.whl (521 kB)\n",
      "Downloading pytest-8.3.3-py3-none-any.whl (342 kB)\n",
      "Downloading streamlit-1.39.0-py2.py3-none-any.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 2.6/8.7 MB 13.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.2/8.7 MB 12.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.9/8.7 MB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.7/8.7 MB 12.1 MB/s eta 0:00:00\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading tqdm-4.66.6-py3-none-any.whl (78 kB)\n",
      "Downloading pydantic_core-2.23.4-cp312-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.9/1.9 MB 11.7 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.11.9-cp312-cp312-win_amd64.whl (436 kB)\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 731.2/731.2 kB 15.1 MB/s eta 0:00:00\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading anyio-4.7.0-py3-none-any.whl (93 kB)\n",
      "Downloading astroid-3.3.5-py3-none-any.whl (274 kB)\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl (220 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading fonttools-4.55.2-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 10.3 MB/s eta 0:00:00\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Downloading httpx-0.28.0-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading isort-5.13.2-py3-none-any.whl (92 kB)\n",
      "Downloading jiter-0.8.0-cp312-none-win_amd64.whl (206 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading kiwisolver-1.4.7-cp312-cp312-win_amd64.whl (55 kB)\n",
      "Downloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
      "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.4/15.5 MB 11.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.9/15.5 MB 11.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 4.2/15.5 MB 7.0 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 5.0/15.5 MB 5.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 6.0/15.5 MB 5.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.9/15.5 MB 6.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.5/15.5 MB 7.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.6/15.5 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.5 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 7.9 MB/s eta 0:00:00\n",
      "Downloading pillow-10.4.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   -------------------------------- ------- 2.1/2.6 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 9.8 MB/s eta 0:00:00\n",
      "Downloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading protobuf-5.29.1-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading pyarrow-18.1.0-cp312-cp312-win_amd64.whl (25.1 MB)\n",
      "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.4/25.1 MB 11.2 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 4.5/25.1 MB 11.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 6.8/25.1 MB 11.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 8.7/25.1 MB 11.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 11.0/25.1 MB 10.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 13.4/25.1 MB 11.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 16.0/25.1 MB 11.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 18.4/25.1 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.0/25.1 MB 11.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.1/25.1 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.9/25.1 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.1/25.1 MB 10.4 MB/s eta 0:00:00\n",
      "Downloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 2.6/6.9 MB 13.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.7/6.9 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/6.9 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.9/6.9 MB 10.6 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading SQLAlchemy-2.0.35-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 9.7 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.8.0-cp312-cp312-win_amd64.whl (883 kB)\n",
      "   ---------------------------------------- 0.0/883.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 883.8/883.8 kB 13.2 MB/s eta 0:00:00\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Downloading watchdog-5.0.3-py3-none-win_amd64.whl (79 kB)\n",
      "Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading lxml-5.3.0-cp312-cp312-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 2.9/3.8 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 14.2 MB/s eta 0:00:00\n",
      "Downloading python_copasi-4.45.296-cp312-cp312-win_amd64.whl (6.5 MB)\n",
      "   ---------------------------------------- 0.0/6.5 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 2.9/6.5 MB 13.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.8/6.5 MB 13.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.5/6.5 MB 12.6 MB/s eta 0:00:00\n",
      "Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "   ---------------------------------------- 0.0/44.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.4/44.5 MB 11.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 4.7/44.5 MB 11.4 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 7.1/44.5 MB 11.5 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 8.9/44.5 MB 10.9 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 10.5/44.5 MB 9.9 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 12.3/44.5 MB 9.8 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 13.6/44.5 MB 9.8 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 13.6/44.5 MB 9.8 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 14.4/44.5 MB 7.7 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 14.9/44.5 MB 7.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 16.3/44.5 MB 7.1 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 17.3/44.5 MB 6.9 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 18.4/44.5 MB 6.7 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 19.4/44.5 MB 6.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 20.7/44.5 MB 6.5 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 22.0/44.5 MB 6.5 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 23.3/44.5 MB 6.4 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 24.4/44.5 MB 6.4 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 25.7/44.5 MB 6.4 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 27.0/44.5 MB 6.3 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 28.0/44.5 MB 6.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 29.4/44.5 MB 6.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 30.7/44.5 MB 6.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 32.0/44.5 MB 6.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 33.6/44.5 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 34.9/44.5 MB 6.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 36.2/44.5 MB 6.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 37.7/44.5 MB 6.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 38.8/44.5 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.6/44.5 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.4/44.5 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.4/44.5 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.7/44.5 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.0/44.5 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.5/44.5 MB 6.0 MB/s eta 0:00:00\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl (51 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Downloading narwhals-1.15.2-py3-none-any.whl (233 kB)\n",
      "Downloading orjson-3.10.12-cp312-none-win_amd64.whl (135 kB)\n",
      "Downloading propcache-0.2.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.18.3-cp312-cp312-win_amd64.whl (90 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: pytz, python-copasi, watchdog, tzdata, typing-extensions, tqdm, tomlkit, toml, tenacity, tabulate, sniffio, smmap, python-dotenv, pyparsing, pyarrow, protobuf, propcache, pluggy, pillow, orjson, numpy, narwhals, mypy-extensions, multidict, mccabe, marshmallow, lxml, kiwisolver, jsonpointer, jiter, isort, iniconfig, httpx-sse, h11, greenlet, frozenlist, fonttools, distro, dill, cycler, coverage, cachetools, blinker, astroid, annotated-types, aiohappyeyeballs, yarl, typing-inspect, tiktoken, SQLAlchemy, scipy, rich, requests-toolbelt, pytest, pylint, pydeck, pydantic-core, plotly, pandas, jsonpatch, httpcore, gitdb, contourpy, anyio, aiosignal, pydantic, matplotlib, httpx, gitpython, dataclasses-json, aiohttp, pydantic-settings, openai, langsmith, copasi_basico, altair, streamlit, langchain-core, langchain-text-splitters, langchain-openai, langchain, langchain-community, langchain-experimental, aiagents4pharma\n",
      "  Attempting uninstall: watchdog\n",
      "    Found existing installation: watchdog 6.0.0\n",
      "    Uninstalling watchdog-6.0.0:\n",
      "      Successfully uninstalled watchdog-6.0.0\n",
      "Successfully installed SQLAlchemy-2.0.35 aiagents4pharma-1.2.1 aiohappyeyeballs-2.4.4 aiohttp-3.11.9 aiosignal-1.3.1 altair-5.5.0 annotated-types-0.7.0 anyio-4.7.0 astroid-3.3.5 blinker-1.9.0 cachetools-5.5.0 contourpy-1.3.1 copasi_basico-0.78 coverage-7.6.4 cycler-0.12.1 dataclasses-json-0.6.7 dill-0.3.9 distro-1.9.0 fonttools-4.55.2 frozenlist-1.5.0 gitdb-4.0.11 gitpython-3.1.43 greenlet-3.1.1 h11-0.14.0 httpcore-1.0.7 httpx-0.28.0 httpx-sse-0.4.0 iniconfig-2.0.0 isort-5.13.2 jiter-0.8.0 jsonpatch-1.33 jsonpointer-3.0.0 kiwisolver-1.4.7 langchain-0.3.7 langchain-community-0.3.5 langchain-core-0.3.15 langchain-experimental-0.3.3 langchain-openai-0.2.5 langchain-text-splitters-0.3.2 langsmith-0.1.147 lxml-5.3.0 marshmallow-3.23.1 matplotlib-3.9.2 mccabe-0.7.0 multidict-6.1.0 mypy-extensions-1.0.0 narwhals-1.15.2 numpy-1.26.4 openai-1.55.3 orjson-3.10.12 pandas-2.2.3 pillow-10.4.0 plotly-5.24.1 pluggy-1.5.0 propcache-0.2.1 protobuf-5.29.1 pyarrow-18.1.0 pydantic-2.9.2 pydantic-core-2.23.4 pydantic-settings-2.6.1 pydeck-0.9.1 pylint-3.3.1 pyparsing-3.2.0 pytest-8.3.3 python-copasi-4.45.296 python-dotenv-1.0.1 pytz-2024.2 requests-toolbelt-1.0.0 rich-13.9.4 scipy-1.14.1 smmap-5.0.1 sniffio-1.3.1 streamlit-1.39.0 tabulate-0.9.0 tenacity-9.0.0 tiktoken-0.8.0 toml-0.10.2 tomlkit-0.13.2 tqdm-4.66.6 typing-extensions-4.12.2 typing-inspect-0.9.0 tzdata-2024.2 watchdog-5.0.3 yarl-1.18.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Wheel filename 'python_copasi-4.24.197_1-cp27-cp27m-manylinux1_i686.whl' is not correctly normalised. Future versions of pip will raise the following error:\n",
      "  Invalid wheel filename (invalid version): python_copasi-4.24.197_1-cp27-cp27m-manylinux1_i686\n",
      "  \n",
      "   pip 25.1 will enforce this behaviour change. A possible replacement is to rename the wheel to use a correctly normalised name (this may require updating the version in the project metadata). Discussion can be found at https://github.com/pypa/pip/issues/12938\n",
      "  DEPRECATION: Wheel filename 'python_copasi-4.24.197_1-cp27-cp27m-manylinux1_x86_64.whl' is not correctly normalised. Future versions of pip will raise the following error:\n",
      "  Invalid wheel filename (invalid version): python_copasi-4.24.197_1-cp27-cp27m-manylinux1_x86_64\n",
      "  \n",
      "   pip 25.1 will enforce this behaviour change. A possible replacement is to rename the wheel to use a correctly normalised name (this may require updating the version in the project metadata). Discussion can be found at https://github.com/pypa/pip/issues/12938\n",
      "  DEPRECATION: Wheel filename 'python_copasi-4.24.197_1-cp27-cp27mu-manylinux1_i686.whl' is not correctly normalised. Future versions of pip will raise the following error:\n",
      "  Invalid wheel filename (invalid version): python_copasi-4.24.197_1-cp27-cp27mu-manylinux1_i686\n",
      "  \n",
      "   pip 25.1 will enforce this behaviour change. A possible replacement is to rename the wheel to use a correctly normalised name (this may require updating the version in the project metadata). Discussion can be found at https://github.com/pypa/pip/issues/12938\n",
      "  DEPRECATION: Wheel filename 'python_copasi-4.24.197_1-cp27-cp27mu-manylinux1_x86_64.whl' is not correctly normalised. Future versions of pip will raise the following error:\n",
      "  Invalid wheel filename (invalid version): python_copasi-4.24.197_1-cp27-cp27mu-manylinux1_x86_64\n",
      "  \n",
      "   pip 25.1 will enforce this behaviour change. A possible replacement is to rename the wheel to use a correctly normalised name (this may require updating the version in the project metadata). Discussion can be found at https://github.com/pypa/pip/issues/12938\n",
      "  DEPRECATION: Wheel filename 'python_copasi-4.24.197_1-cp34-cp34m-manylinux1_i686.whl' is not correctly normalised. Future versions of pip will raise the following error:\n",
      "  Invalid wheel filename (invalid version): python_copasi-4.24.197_1-cp34-cp34m-manylinux1_i686\n",
      "  \n",
      "   pip 25.1 will enforce this behaviour change. A possible replacement is to rename the wheel to use a correctly normalised name (this may require updating the version in the project metadata). Discussion can be found at https://github.com/pypa/pip/issues/12938\n",
      "  DEPRECATION: Wheel filename 'python_copasi-4.24.197_1-cp34-cp34m-manylinux1_x86_64.whl' is not correctly normalised. Future versions of pip will raise the following error:\n",
      "  Invalid wheel filename (invalid version): python_copasi-4.24.197_1-cp34-cp34m-manylinux1_x86_64\n",
      "  \n",
      "   pip 25.1 will enforce this behaviour change. A possible replacement is to rename the wheel to use a correctly normalised name (this may require updating the version in the project metadata). Discussion can be found at https://github.com/pypa/pip/issues/12938\n",
      "  DEPRECATION: Wheel filename 'python_copasi-4.24.197_1-cp35-cp35m-manylinux1_i686.whl' is not correctly normalised. Future versions of pip will raise the following error:\n",
      "  Invalid wheel filename (invalid version): python_copasi-4.24.197_1-cp35-cp35m-manylinux1_i686\n",
      "  \n",
      "   pip 25.1 will enforce this behaviour change. A possible replacement is to rename the wheel to use a correctly normalised name (this may require updating the version in the project metadata). Discussion can be found at https://github.com/pypa/pip/issues/12938\n",
      "  DEPRECATION: Wheel filename 'python_copasi-4.24.197_1-cp35-cp35m-manylinux1_x86_64.whl' is not correctly normalised. Future versions of pip will raise the following error:\n",
      "  Invalid wheel filename (invalid version): python_copasi-4.24.197_1-cp35-cp35m-manylinux1_x86_64\n",
      "  \n",
      "   pip 25.1 will enforce this behaviour change. A possible replacement is to rename the wheel to use a correctly normalised name (this may require updating the version in the project metadata). Discussion can be found at https://github.com/pypa/pip/issues/12938\n",
      "  DEPRECATION: Wheel filename 'python_copasi-4.24.197_1-cp36-cp36m-manylinux1_i686.whl' is not correctly normalised. Future versions of pip will raise the following error:\n",
      "  Invalid wheel filename (invalid version): python_copasi-4.24.197_1-cp36-cp36m-manylinux1_i686\n",
      "  \n",
      "   pip 25.1 will enforce this behaviour change. A possible replacement is to rename the wheel to use a correctly normalised name (this may require updating the version in the project metadata). Discussion can be found at https://github.com/pypa/pip/issues/12938\n",
      "  DEPRECATION: Wheel filename 'python_copasi-4.24.197_1-cp36-cp36m-manylinux1_x86_64.whl' is not correctly normalised. Future versions of pip will raise the following error:\n",
      "  Invalid wheel filename (invalid version): python_copasi-4.24.197_1-cp36-cp36m-manylinux1_x86_64\n",
      "  \n",
      "   pip 25.1 will enforce this behaviour change. A possible replacement is to rename the wheel to use a correctly normalised name (this may require updating the version in the project metadata). Discussion can be found at https://github.com/pypa/pip/issues/12938\n",
      "  DEPRECATION: Wheel filename 'python_copasi-4.24.197_1-cp37-cp37m-manylinux1_i686.whl' is not correctly normalised. Future versions of pip will raise the following error:\n",
      "  Invalid wheel filename (invalid version): python_copasi-4.24.197_1-cp37-cp37m-manylinux1_i686\n",
      "  \n",
      "   pip 25.1 will enforce this behaviour change. A possible replacement is to rename the wheel to use a correctly normalised name (this may require updating the version in the project metadata). Discussion can be found at https://github.com/pypa/pip/issues/12938\n",
      "  DEPRECATION: Wheel filename 'python_copasi-4.24.197_1-cp37-cp37m-manylinux1_x86_64.whl' is not correctly normalised. Future versions of pip will raise the following error:\n",
      "  Invalid wheel filename (invalid version): python_copasi-4.24.197_1-cp37-cp37m-manylinux1_x86_64\n",
      "  \n",
      "   pip 25.1 will enforce this behaviour change. A possible replacement is to rename the wheel to use a correctly normalised name (this may require updating the version in the project metadata). Discussion can be found at https://github.com/pypa/pip/issues/12938\n",
      "  DEPRECATION: Wheel filename 'python_copasi-4.27.214_1-cp27-cp27m-manylinux1_x86_64.whl' is not correctly normalised. Future versions of pip will raise the following error:\n",
      "  Invalid wheel filename (invalid version): python_copasi-4.27.214_1-cp27-cp27m-manylinux1_x86_64\n",
      "  \n",
      "   pip 25.1 will enforce this behaviour change. A possible replacement is to rename the wheel to use a correctly normalised name (this may require updating the version in the project metadata). Discussion can be found at https://github.com/pypa/pip/issues/12938\n",
      "  DEPRECATION: Wheel filename 'python_copasi-4.27.214_1-cp27-cp27mu-manylinux1_x86_64.whl' is not correctly normalised. Future versions of pip will raise the following error:\n",
      "  Invalid wheel filename (invalid version): python_copasi-4.27.214_1-cp27-cp27mu-manylinux1_x86_64\n",
      "  \n",
      "   pip 25.1 will enforce this behaviour change. A possible replacement is to rename the wheel to use a correctly normalised name (this may require updating the version in the project metadata). Discussion can be found at https://github.com/pypa/pip/issues/12938\n",
      "  DEPRECATION: Wheel filename 'python_copasi-4.27.214_1-cp34-cp34m-manylinux1_x86_64.whl' is not correctly normalised. Future versions of pip will raise the following error:\n",
      "  Invalid wheel filename (invalid version): python_copasi-4.27.214_1-cp34-cp34m-manylinux1_x86_64\n",
      "  \n",
      "   pip 25.1 will enforce this behaviour change. A possible replacement is to rename the wheel to use a correctly normalised name (this may require updating the version in the project metadata). Discussion can be found at https://github.com/pypa/pip/issues/12938\n",
      "  DEPRECATION: Wheel filename 'python_copasi-4.27.214_1-cp35-cp35m-manylinux1_x86_64.whl' is not correctly normalised. Future versions of pip will raise the following error:\n",
      "  Invalid wheel filename (invalid version): python_copasi-4.27.214_1-cp35-cp35m-manylinux1_x86_64\n",
      "  \n",
      "   pip 25.1 will enforce this behaviour change. A possible replacement is to rename the wheel to use a correctly normalised name (this may require updating the version in the project metadata). Discussion can be found at https://github.com/pypa/pip/issues/12938\n",
      "  DEPRECATION: Wheel filename 'python_copasi-4.27.214_1-cp36-cp36m-manylinux1_x86_64.whl' is not correctly normalised. Future versions of pip will raise the following error:\n",
      "  Invalid wheel filename (invalid version): python_copasi-4.27.214_1-cp36-cp36m-manylinux1_x86_64\n",
      "  \n",
      "   pip 25.1 will enforce this behaviour change. A possible replacement is to rename the wheel to use a correctly normalised name (this may require updating the version in the project metadata). Discussion can be found at https://github.com/pypa/pip/issues/12938\n",
      "  DEPRECATION: Wheel filename 'python_copasi-4.27.214_1-cp37-cp37m-manylinux1_x86_64.whl' is not correctly normalised. Future versions of pip will raise the following error:\n",
      "  Invalid wheel filename (invalid version): python_copasi-4.27.214_1-cp37-cp37m-manylinux1_x86_64\n",
      "  \n",
      "   pip 25.1 will enforce this behaviour change. A possible replacement is to rename the wheel to use a correctly normalised name (this may require updating the version in the project metadata). Discussion can be found at https://github.com/pypa/pip/issues/12938\n"
     ]
    }
   ],
   "source": [
    "#!pip install aiagents4pharma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Models Tool - Demonstration\n",
    "\n",
    "This notebook demonstrates how to use the `search_models` tool for querying biological models. It includes the following steps:\n",
    "1. Import the package and tool.\n",
    "2. Initialize the tool.\n",
    "3. Run the tool with a sample query.\n",
    "4. Display the results.\n",
    "\n",
    "\n",
    "## 1. Import Required Packages and Tools\n",
    "First, we'll import the necessary classes and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the `SearchModelsTool` class from search_models.py\n",
    "from aiagents4pharma.talk2biomodels.tools.search_models import SearchModelsTool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize the Search Models Tool\n",
    "\n",
    "Here, we initialize the `SearchModelsTool`, which we will use to run our search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SearchModelsTool\n",
    "search_tool = SearchModelsTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the Search Models Tool\n",
    "\n",
    "In this step, we invoke the `search_models` tool with a sample query. The tool takes a query string as input and returns a formatted table of results.\n",
    "\n",
    "For demonstration, we'll use the query: \"search model on inflammatory bowel disease.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the OpenAI API key directly in the notebook (temporary method)\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_api_key\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search query\n",
    "query = \"search model on inflammatory bowel disease\"\n",
    "\n",
    "# Run the tool with the query\n",
    "search_results = search_tool._run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Display the Results\n",
    "\n",
    "The results returned by the tool will be displayed as a formatted table, including:\n",
    "- Model ID (as clickable links)\n",
    "- Model Name\n",
    "- Format\n",
    "- Submission Date\n",
    "\n",
    "This makes it easy to explore and interpret the search output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| #  | BioModel ID                                                  | BioModel Name                                                                                                  | Format | Submission Date |\n",
      "|----|-------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|--------|------------------|\n",
      "| 1  | [MODEL1109130000](https://www.ebi.ac.uk/biomodels/MODEL1109130000) | Thiele2013 - Human metabolism global reconstruction (Recon 2)                                                | SBML   | 2011-09-12       |\n",
      "| 2  | [MODEL1311110000](https://www.ebi.ac.uk/biomodels/MODEL1311110000) | Smallbone2013 - Human metabolism global reconstruction (recon 2.1)                                            | SBML   | 2013-11-11       |\n",
      "| 3  | [MODEL1311110001](https://www.ebi.ac.uk/biomodels/MODEL1311110001) | Smallbone2013 - Human metabolism global reconstruction (recon 2.1x)                                           | SBML   | 2013-11-11       |\n",
      "| 4  | [MODEL1703310000](https://www.ebi.ac.uk/biomodels/MODEL1703310000) | MODEL1703310000_url.xml                                                                                       | SBML   | 2017-03-30       |\n",
      "| 5  | [MODEL2307180001](https://www.ebi.ac.uk/biomodels/MODEL2307180001) | Zerrouk2023 - Large scale computational modeling of the M1 synovial macrophage in rheumatoid arthritis         | SBML   | 2023-07-17       |\n",
      "| 6  | [MODEL2307180002](https://www.ebi.ac.uk/biomodels/MODEL2307180002) | Zerrouk2023 - Large scale computational modeling of the M2 synovial macrophage in rheumatoid arthritis         | SBML   | 2023-07-17       |\n"
     ]
    }
   ],
   "source": [
    "# Display the search results\n",
    "print(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Key Takeaways\n",
    "\n",
    "- You can use the `SearchModelsTool` to search for biological models using specific queries.\n",
    "- The results are structured in a user-friendly table format, making them easy to analyze and interpret.\n",
    "\n",
    "Feel free to modify the query to search for different models based on your requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
